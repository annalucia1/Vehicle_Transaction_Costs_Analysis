{"cells":[{"cell_type":"code","source":["# vehicle transaction costs project\n# This project leverages transaction orders to extract useful information with regards to vehicle transactions costs and created metrics on vehicle transaction costs, particularly official costs for each order"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["dbutils.fs.mkdirs('/FileStore/tables/snap')"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# coding=utf-8\nimport pyspark\nfrom pyspark.sql.functions import UserDefinedFunction\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql import Row \nfrom pyspark.sql import Column\nimport pyspark.sql.functions as func\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"snap_data_challenge\") \\\n    .config(\"spark.some.config.option\", \"value\") \\\n    .getOrCreate()\nitems = spark.read.csv('/FileStore/tables/snap/order_order_items.csv', sep = \",\", header='true', inferSchema='true')\norders = spark.read.csv('/FileStore/tables/snap/order_orders.csv', sep = \",\", header='true', inferSchema='true')\norders = orders.withColumnRenamed(\"id\", \"order_id\")\n# items = items.withColumn(\"created_at\", items['created_at'].cast(TimestampType())) \\\n#               .withColumn(\"updated_at\", items['updated_at'].cast(TimestampType())) \n#               .withColumn(\"order_id\", items['order_id'].cast(IntegerType()))\n# orders = orders.withColumn(\"created_at\", orders['created_at'].cast(TimestampType())) \\\n#               .withColumn(\"updated_at\", orders['updated_at'].cast(TimestampType())) \n#               .withColumn(\"order_id\", orders['order_id'].cast(IntegerType())) \\\n#               .withColumn(\"application_id\", orders['application_id'].cast(IntegerType()))\nitems.createOrReplaceTempView(\"items\")\norders.createOrReplaceTempView(\"orders\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["orders.dtypes"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["items.dtypes"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# explore orders data\norders.select('order_id', 'application_id', 'created_at').describe().show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["print orders.count()\nprint orders.select('order_id').distinct().count()\n# order id is the unique identifier in orders dataset\nprint orders.select('application_id').distinct().count()\n# one application id has several order ids\nprint orders.select('application_id', 'created_at').distinct().count()\n# 'application_id' and 'created_at' can uniquely identify an order in the data"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# no missing values in application_id, created_at or order_id\norders = orders.na.drop(subset = ['application_id'])\norders = orders.na.drop(subset = ['order_id'])\norders = orders.na.drop(subset = ['created_at'])\norders.count()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# extract the most recent order for each applicaiton\nlatest_order = orders.select('application_id','created_at') \\\n                      .orderBy('created_at', ascending = False) \\\n                      .groupby('application_id') \\\n                      .agg(func.first('created_at').alias('created_at'))\n# merge in the order id to prepare for the join with order items data\norders_recent = orders.join(latest_order,  (latest_order['created_at'] == orders['created_at']), 'inner' ).select(orders['order_id'], latest_order['application_id'], latest_order['created_at'])\nprint orders_recent.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["print orders_recent.count()\norders_recent.show()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# explore order items data\nprint items.count()\nprint items.select('id').distinct().count()\nprint items.select('order_id').distinct().count()\n# drop missing values in order_id\nitems = items.na.drop(subset = ['order_id'])\nprint items.count()\nitems = items.na.drop(subset = ['created_at'])\nprint items.count()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# item types for each order\nitems.select('name').distinct().head(50)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%sql\nSELECT DISTINCT item_type\nFROM items"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["items = items.select('order_id', 'name', 'item_type', 'price_cents')"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["items = items.withColumn('name', func.trim(func.lower(items['name']) ) ) \\\n             .withColumn('item_type', func.trim(func.lower(items['item_type']) ) )"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Reclassify the items into six types: Documentation Fee, Electronic Title, CA Tire, License, registration/transfer related(Smog, Transfer, Registration), and Vehicle \nfor string in ['doc', 'title', 'tire', 'license']:    \n    items = items.withColumn(string, func.when( items['name'].contains(string), items['price_cents'] ).otherwise(0) )\nitems = items.withColumn('vehicle', func.when( items['name'] == \"vehicle\", items['price_cents'] ).otherwise(0) )\nitems = items.withColumn('reg_trans_smog', func.lit(0))\nfor string in [ 'reg', 'trans', 'smog', 'reg/trans']:    \n    items = items.withColumn('reg_trans_smog', func.when( items['name'].contains(string), items['price_cents'] ).otherwise(items['reg_trans_smog']) )"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# data quality check for reg_trans_smog\nitems.select('reg_trans_smog').show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# extract the pricing information for each of the above six types\nitems = items.groupby('order_id').agg(func.sum(items['doc']).alias('doc'), func.sum(items['title']).alias('title'), func.sum(items['tire']).alias('tire'), func.sum(items['license']).alias('license'), func.sum(items['reg_trans_smog']).alias('reg_trans_smog'), func.sum(items['vehicle']).alias('vehicle') )"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["items = items.withColumn('total_official',items['reg_trans_smog'] + items['tire'] + items['license'])"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# only keep the most recent order information for each application by inner joining order_recent dataset\nres =  items.join(orders_recent,  orders_recent['order_id'] == items['order_id'], 'inner').select(orders_recent['order_id'], orders_recent['application_id'], orders_recent['created_at'], items['doc'],items['title'], items['tire'], items['license'], items['reg_trans_smog'], items['vehicle'], items['total_official'] )\nres = res.orderBy('order_id')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# data quality check\nres = res.orderBy('order_id')\nres.show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["print res.count()\nres.select('reg_trans_smog').describe().show()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# export results\nres.createOrReplaceTempView(\"res\")"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["%sql\nSELECT *\nFROM res"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# test code\n# orders.withColumn(\"first\", )\n# have row number and only keep the first one by filter\norders = spark.sql(\"SELECT id, status, person_id, application_id, vehicle_id, first_value(created_at) over(partition by application_id order by created_at desc) as created_at, updated_at, offer_id, dealer_id, vehicle_mileage, contract_package_id, miles_per_year, dealer_person_id, subscription_id FROM orders\")\n\n\ncnt_applicationID_created = orders.groupby('application_id','created_at').count()\n# cnt_applicationID_created.show()\n# cnt_applicationID_created.orderBy('count', ascending = False).show()\ncnt_applicationID_created.orderBy('created_at', ascending = False).show()\n# cnt_applicationID_created.count()\n\n# latest_order = orders.select('application_id','created_at', 'order_id') \\\n#                       .groupby('application_id','created_at') \\\n#                       .count() \\\n#                       .orderBy('count', ascending = False) \\\n#                       .groupby('application_id') \\\n#                       .agg(func.first('created_at'))\n\n# another way to write latest_order\nlatest_order = spark.sql(\"SELECT id, application_id, first_value(created_at) over(partition by application_id order by created_at desc) as created_at, updated_at, offer_id, dealer_id, vehicle_mileage, contract_package_id, miles_per_year, dealer_person_id, subscription_id FROM orders\")\n\nudf = UserDefinedFunction(lambda x: re.sub(',','',x), StringType())\nnew_df = df.select(*[udf(column).alias(column) for column in df.columns])"],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"snap","notebookId":4456208024381719},"nbformat":4,"nbformat_minor":0}
